% \section{Abstract}

\section{Forward}

The imbalance between compute and memory capacity for data
center servers has only increased over the past decade.
Simultaneously networks have doubled in capacity at an
increasing rate and have integrated line rate
programmability into many commodity chips. These trends have
yielded various research proposals for attacking the
\textit{memory wall} with fast networks. Memory
disaggregation proposes the addition of pools of far-memory
attached over a network to clusters of compute machines,
with the promise that large shared pools will decrease
memory stranding and increase overall memory utilization.

Latency is the chief challenge in realizing practical memory
disaggregation. Low-latency interconnects such as RDMA have
intra-rack round trip latencies on the order of 1-2$\mu$s.
In contrast to local memory DRAM access times of 50-100ns
RDMA latency is a 20x overhead. This disparity prevents many
data structures, and system functions from being deployable
for remote memory. Existing systems have amortized the
network cost by porting slower subsystems i.e swap devices
~\cite{fastswap, legoos}\todo{add more}. 

These systems avoid a key feature of local memory
\textit{sharing}. Shared data structures in remote memory
can suffer abysmal performance when accessed concurrently.
Both traditional lock based and optimistically concurrent
data structures suffer abysmal performance when ported to
remote memory. Lock based algorithms have inflated critical
section sizes due to round trip delays, and optimistic
approaches suffer from stale caches under contention, and
the increased cost of reading to synchronize caches. In
general shared structures are hard to port to remote memory.

%% Todo this is my research statement work hard on it.
My work focuses on the design of algorithms and data
structures for remote memory.  A key insight of my work is
that the performance pitfalls of remote memory arise from
memory not having colocated compute to serialize operations.
We note that this pitfall is unnecessary because the network
implicitly serializes each operation during transit and
programable elements within the network can administrate
algorithm level serialization at line rate. With this
observation in mind we design shared far memory systems
using programmable devices such as NIC's and switches to
accelerate performance.

This research summary covers three projects which illustrate
how these devices can be used to improve optimistic data
structures, lock-based structures, and finally, shared
structures in general.  The first system \textit{Swordbox}
demonstrates that by caching the operations of an optimistic
algorithm on a programmable switch contention can be
entirely removed in network enabling up to 40x improvement
in throughput and 300x reduction in tail latency for
contested workloads. The second project \textit{RCuckoo}
shows how with careful algorithm design and the judicial use
of RDMA features a traditional local memory algorithm can be
ported to remote memory. Finally this work presents an
outline for general data structure design for remote memory
using a programmable switch to remove contention in the
general case.


\section{Optimistic Data Structures}

Pointers are an issue for far memory data structures. Each
pointer dereference requires an expensive round trip.
Structures like linked lists, and trees lead to
\textit{pointer chasing}, when many round trips are required
to finish each operation. Some proposals have called for
pointer chasing primitives built into networking
hardware~\cite{prisim, supernic}, but none are available in
commodity hardware. In the absence of this hardware
algorithmic techniques are required to reduce the number of
pointer dereferences per operation.

\textit{Swordbox} makes the observation that within a rack a
TOR sees all traffic. Therefore, a programmable switch can
observe all updates to a shared data structure in a
perfectly serialized order. Opportunistic requests which
would otherwise fail can be corrected in flight by the
switch with it's cached up to date information so that no
operations need fail.

We demonstrate this by implementing swordbox in P4 and
demonstrate it's performance benifits for a remote memory
system Clover~\cite{clover} a system for persistant remote
memory. Clients in clover persist their key-value writes by
appending to a shared linked list. Appends fail if they are
made to any location other than the tail of the list.
Concurrent writes lead to failed request in which clients
race and pointer chase for a successful requst for the tail.
Swordbox caches the tail pointer on the switch, and when
stale request are seen they are updated at line rate and
made to succeed.  We demonstrate that under contention
swordbox can improve throughput by nearly 35x and reduce
tail latency by 300x. \todo{add a figure of the failure
rate, and of clover vs swordbox.}

\section{RCuckoo}

Not all data structures are amenable to oportunistic
updates, but traditional locking port poorly to remote
memory. Acquiring, and then releasing a lock requires at
minimum two round trips, a fact which not only increases the
minimum operation duration, but which sets a minimum
duration on critical sections. A system with a 2us round
trip time, and a single global lock can only perform 500,000
operations per second in the best case (meger numbers when
considering that decakes old key value stores acheive 10's
of millions of requests per second ~\cite{herd}). Fine
grained locking is a requirement. Unfortunatly fine grained
locking suffers from a duel problem, deadlock free lock
acquisition requires a round trip per lock inflating
operation time. 

With RDMA atomics many locks can be aquired in a single
operation, but only if they are within the word width of the
RDMA atomic (64 bits). Fine grained locking is therefore a
challenge of achieving good lock locality.

With this in mind we investigate porting cuckoo hashing to
remote memory. Cuckoo hashing has long been known to perform
well with RDMA reads as lookups must search at most 2
locations~\cite{pilaf, farm}. The complexity of cuckoo
hashing is pushed to writes which perform swaps randomly
throughout the table. We develop a new algorithm for
locality aware cuckoo hashing. Both hash location are with
high probabiltiy located close together. Insertions are
therefore more likely to be localized to a small reigion of
the tabe rather than random, and the locks can be aquired in
few round trips. In addition we use locality to improve
searching for hash table openings using locality aware
search (A*) to find minimal distance insertion paths. We
achieve on average 2 round trips per insertion and
demonstrate that we out perform state of the art remote
memory hashing algorithms in simulation.

\todo{add the figure of the A* search and the number of
round trips per lock}


\section{Black Box Disaggregation}

A question remains about general data structure design for
remote memory. while high performanc can be achieved through
careful data structure design, is it possible enable general
data structure design for remote memory? My future research
direction aims to explore this question.

Prior work on NUMA systems has shown that highly concurrent
data structures can be desigend in geneal with a technqiue
known as \textit{node replication}. All operations to a
shared structure are made by appending the operations to a
shared log. Clients wishing to commit operations first read
the log, construct the dat structure locally, and then
append to the end of the log their new operation~\cite{bbd}.

This technique experiences the same contention issues as
clover in that multiple clients race for the tail of the
list, however on NUMA nodes the memory latency is low enough
that the technqiue scales well enough for practical
purposes. 

We propose a similar technqiue for remote memory, with the
addition that switch, or programmable nic close to memory be
used to remove contention from the shared list. The switch
or NIC can provide two fold services. The first of which is
to steer appends to the shared list to the end of the list
enabling the success of each client request. Second when
clients read the shared log, and are unaware of the tail
location, the switch can inflate the size of the reads in
flight by modifying the RDMA read request. 

Using these techniques black box disaggregation can enable
generic high performance shared data structures for remote
memory.

\todo{include a diagram of the system}.

\section{Conclusion}
