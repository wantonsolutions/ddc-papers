\section{Intro}
\label{sec:intro}

%%State of the world
Disaggregated computing promises higher resource density, increased
power-efficiency, and flexible application scalability in datacenters.
While enticing, these benefits have remained mostly untapped due to the proportionally large
overhead of accessing remote resources. Nowhere is this disparity more
noticeable than remote memory. Separating CPUs last level cache from
their main memory incurs roughly a 20x overhead (approximately
50\textit{ns} to 1\textit{us}).  The cost is only acceptable for
select asynchronous workloads, such as paging out infrequently touched
data~\cite{gms}, but are entirely unrealistic when multiple CPUs
requires consistency for frequent reads and writes to remote memory.
Figure~\ref{fig:overview} illustrates resource placement in a
disaggregated rack in contrast to traditional servers.

Researchers and industry leaders have proposed techniques which reduce
cost of write contention with regard to remote
memory~\cite{aguilera2019designing,cell,sonuma,storm,clover}. A common
goal among them is to provide $O(1)$ read and write costs in the
common case. To achieve this strategy such as memory versioning,
checksums, and memory enforced serialization have been
proposed~\cite{aguilera2019designing}.




%%our position

\begin{figure*}
      \centering
      \includegraphics[width=0.95\textwidth]{fig/overview.png}
      %%
      \caption{Anatomy of a disaggregated rack. On the left a
      traditional rack with processors colocated with their memory
      interconnected by a switch. On the right is a high density
      disaggregated rack with processors separated from their memory
      by a top of rack switch. Stars mark locations for memory access
      serialization. Red denotes traditional processor centric
      serialization~\cite{ memc3, cell, sonuma, storm, clover}, blue marks a
      memory centric architecture~\cite{aguilera2019designing}, and
      green marks a switch centric solution similar in spirit to
      proposed middle box solutions~\cite{254120}.
      \label{fig:overview}
      %%
      }
\end{figure*}


This work makes the contention that a programmable switch is an ideal
centralized point at which to implement a remote memory controller.
for rack scale disaggregation.  Prior work has suggested the need for
a distributed memory controller~\cite{254120}. But none have been
built or proposed with existing hardware. We posit that if all remote
reads and writes are performed within a rack using RDMA a programmable
top of rack switch (TOR) will see every memory operation. This fact
allows it to act as a centralized serialization point, where the last
instance of concurrency between the reads and writes of remote CPUs is
the egress port of the switch. The switch can therefore notify CPUs
which contest the same memory regions that their writes have failed
within half an RTT, whereas performing the notify at memory requires a
full RTT. In addition to the fast rejection of out of date writes,
modern programmable switchs \textit{currently} have the ability to
maintain memory version numbers, and to store lists of CPU's which
wish to be notified upon a write occurring to a shared memory location
via a multicast of the write packet. This simple mechanism notifies
CPU's which share a remote region that their local cache is dirty
within half of an RTT of the write being issued.
Figure~\ref{fig:notify} illustrates how switch centric memory
management simplifies a notification protocol. 

%%Struggles
A key problem with using a switch as a memory controller is its
available memory. For context a Barefoot Tofino has 50-100MB of
programmable SRAM. By default this SRAM is used as buffers.
Reallocating buffer memory for storage trades off the usability of a
switch as a packet forwarding device. Therefore any use SRAM for
additional application must be carefully considered. Each shared
region must be bookmarked with a version number, and a list of
\textit{subscriber} CPU's must be maintained.  Maintaining version
numbers for byte addressable memory is unrealistic as the number of
versions would grow with the size of memory, and because a remote read
for a single byte of data is largely impractical. We assume that
remote memory is at least accessed in the form of pages or blocks
(likely 4K) which reduces the number of version numbers which must be
maintained.  Maintaining notify groups is a larger problem as each
shared region requires a list of CPUs with read/write access. As the
number of CPU's grows so too does the per block memory requirement of
the switch.  We place the responsibility of maintaining the read/write
access list to the cores themselves.  Prior to accessing a region a
core must be admitted via con census.  When a write occurs, the
writing node appends the list of cores which share the recon to the
packet. The switch parses the packet for the list and broadcasts the
notify message to the affected cores. While this adds bandwidth
overhead to each write it significantly reduces memory usage on the
switch where resources are tight. Figure~\ref{fig:notify} illustrates
the placement of memory state, alongside a notify algorithm in the
context of 3 distinct resource centric architectures.

%%Position
We consider our use of a programmable switch as a remote memory
controller to be a disaggregation primitive upon which other
disaggregated systems and algorithms can be layered. We expose a
notification API as the lowest level interface with which applications
can utilize the distributed memory controller (\textit{Publish()},
\textit{Subscribe()}). To show it's applicability to existing
disaggregated systems we build both a cache coherent write interface
similar to soNUMA~\cite{sonuma}, and transactional interface upon the
notify API. We port three existing disaggregated systems
Storm~\cite{storm}, Clover~\cite{clover}, and Cell~\cite{cell} and
demonstrate throughput improvements for write intensive workloads
without degrading the performance of reads.


\section{Prototype}
%% WORDS
Prior remote memory sysetms require the use of CPU's on remote
machines to coordinate RDMA~\cite{cell,sonuma,storm,erpc,farm}. Remote
CPU's provide RDMA serialization and simplify consistancy for
distributed data structures. Disaggregated memory poses a new problem:
\textit{How can remote memory be coordinated without a remote CPU?}.

%%
\todo{Separate the transparent from the non trasparent world}
\todo{Cite the job throughput paper}
Clover is the first attempt to have fast consistent remote memory
without any datapath coordination via remote CPU~\cite{clover}. Other
recent approaches such as Remote Reigons~\cite{reigons} discount
remote consistancy, and HP's the machine requires computation in
remote memory, which relies on non existant
hardware~\cite{aguilera2019designing}.

%%
Clover proposes that disagregated datastructes seperate their
computational concerns into distinct responsibilities. Mainly memory
servers, which passivle accepty RDMA requests, Clients which issues read and
writes to the remote memory banks, and Metadata severs which
centralize and keep consistant the shared metadata of the disagregated
datastructures.

Through their experimentation they find that ideal throughput is
gained by placing client shared metadata out of datapath entirely, and
updating it opprotunistically. Placing a metadata coordinater in the
datapath quickly leads to a performance bottlenck. Their algorithm
concetrates on maximizing read operations, and allows for lockless
line rate reads in the absence of writes. In the presence of writes
however clovers operation throughput decreases due to contention. When
concurrent writes contest the same data a race occurs in which the
fastest writer wins. The slower writer will fail, and is forced to
retry it's write after searching through clovers remote data structure
for the next write location. On write heavy workloads these race
conditions happen frequently~\ref{fig:conflicts}, which leads to a
sharp decrease in overall throughput.

\begin{figure}
    \includegraphics[width=0.45\textwidth]{fig/write_conflicts.pdf}
    \caption{Clover write conflicts grow with the number of clients
    (50\% write zipf 0.99 distribution)}
    \label{fig:conflicts}
\end{figure}


%% what are we discussing
Clover's write strategy is opprotunistc, in that it attempts to make
multiple updates without aquiring locks, in the hope that no conflicts
occur. When they do occur it's just job of the writer to reconcile the
conflict. This opprotunism amortizes the cost of lock aquisition when
contention is low, providing average case O(1) read/write and is used
in many high throughput concurrent datastructures.

\todo{add a description of the reconciliation process}

%%
We propose a middleground betwen prior centralized approaches, and
clover's out of datapath metadata separation. Our insite is that by
caching small ammount of a disaggregated data structures metadata in a
centralized location, write conflicts can be resolved in the data path
allowing for conflict free full read and write throughput of
disaggregated data structures.

%%
Using Clover as a platform to prove our concept we design a
ligthweight middle box algorithm which intercepts clovers RDMA read
and write requets, caches a small ammount (64 byte per key) ammount of
structural meta data and resolves write conflicts within the data
path. 

%%
Our algorithm is implemented in DPDK, but is designed to have
extremely low space and computational overhead making it ideals for
network devices such as programable switches and NICSs.



\pagebreak


%% The high level pitch about remote memory.
Far memory projects typically have a remote CPU which is used to
coordinate access to remote resources (cite all object systems). In a
disagregated system there is no remote CPU, therefore the coordination
of reads and writes to remote locations must be done localy. For
performance local caches of remote resources can be used to organize
access to remote resources. For data structures which require
consistancy this creates a problem as stale caches can lead to data
structure corruption.

\section{What we actually built}

Our system caches metadata for remote datastructure on centralized
networking devices. Our prototype is implemented in DPDK, however our
algoritim could be implemented on a programmable switch or
programmable nic as long as it sees requests to remote memory. 

%%kinds of devices
A programmable TOR or our DPDK switch (which behaves as one) is ideal
for disagregated structures that potentially span multiple memory
servers , while a programable NIC is limited to the memory it is
attached to. 

%%Technique example
The purpose of our technique is to resolve write conflicts to remote
memory. As an example of a conflict take a linked list implemented as
a remote data structure with a single operation, \textit{appendTail}.
This operation ensures that the next write to the data structre writes
to the tail of the linked list. This operation requires two steps.
First a writer sends and RDMA write to the remote memory which writes
the data value for the new tail. After the data is written a second
operations consisting of an RDMA check and set is issued to the old
tail which replaces it's NULL next pointer with the address of the
newly written tail.

This operation works every time in the single threaded case as the
tail of the linked list is never moved by another process. Consider
however the mutithreaded case in which two writer both attempt to
execute \textit{appendTail} concurrently. Both issue their first write
to remote memory successfully and then attempt to run an RDMA CNS on
the tail of the old list. This results in a race condition where one
process succeeds, and the other will fail. The process which executes
the CNS second fails because rather than finding a tail with a next
value of NULL, it finds the now penulimate member of the linked list
which now points to the value issued by the process which won the
race. 

The process which lost the race now needs to engage in \textit{Pointer
chasing} It must itterativly issue reads of the linked list untill it
finds the location of the new tail. At which point it can reissue a
CNS to make the new tail point to it's value. This reconcilation
algorithm of pointer chaising must be run each time a conflict occurs.
For highly contested structures the number of retries can grow
quickly, leading to large and unpredictable tail latencies.

In the case of clover this exact scenerio occurs when key are write
contested. Their experiments with a zipf distribution on their keys
sees a \todo{5x} reduction in throughput.

%% What do we actually do
If a central arbeter where to observer the writes to this linked list
it would notice that the second cns does not need to fail, it simply
needs to be redirected to point at the new tail of the list. Our
contention is that such an arbeter can be simply implemnted in network
to significantly improve the write throughput to contested keys by
monitering writes to shared locations, and using data structure
specific information to resolve conflicting writes in the data path
directly.

In the case of clover we cache the tail of the linked list for each
key in clovers key value store. This results in an \textit{O(n)}
overhead where n is the number of keys. In our case for a key value
store consisting of 10k keys we need to store a key mapping and value
for each (both 64 bits) resulting in a total in network storage of
80KB. Note that this O(n) overhead is only a small fraction of clovers
metadata. Each key has a versioned history of writes, however only the
tail of the list is required to accelerate writes.






